{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "split-then-refine-car.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackliusr/data-science/blob/main/split_then_refine_car.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s3VjY_bpXR8"
      },
      "source": [
        "This Colab contains the Official demo of our AAAI21 paper:\n",
        "\n",
        "[**Split then Refine: Stacked Attention-guided ResUNets for Blind Single Image Visible Watermark Removal**](https://arxiv.org/abs/2012.07007)\n",
        "\n",
        "Xiaodong Cun, Chi-Man Pun*\n",
        "\n",
        "University of Macau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E246uTxrh3EX",
        "outputId": "9a28068e-07e1-4b75-e274-b8e154565888"
      },
      "source": [
        "! wget -O car.jpg https://i.i-sgcm.com/new_cars/cars/12258/12258_g34_b.jpg\n",
        "! pwd \n",
        "! ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-19 01:15:37--  https://i.i-sgcm.com/new_cars/cars/12258/12258_g34_b.jpg\n",
            "Resolving i.i-sgcm.com (i.i-sgcm.com)... 152.199.1.124\n",
            "Connecting to i.i-sgcm.com (i.i-sgcm.com)|152.199.1.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172986 (169K) [image/jpeg]\n",
            "Saving to: ‘car.jpg’\n",
            "\n",
            "car.jpg             100%[===================>] 168.93K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-04-19 01:15:37 (10.8 MB/s) - ‘car.jpg’ saved [172986/172986]\n",
            "\n",
            "/content\n",
            "car.jpg  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r73ZJv4bpTVD",
        "outputId": "0d7f0a6b-e36a-499d-edc1-23f347c8f0f0"
      },
      "source": [
        "# download the necessary componments\n",
        "! rm -rf *\n",
        "! git clone https://github.com/vinthony/deep-blind-watermark-removal.git # get code from github\n",
        "! gdown https://drive.google.com/uc?id=1KpSJ6385CHN6WlAINqB3CYrJdleQTJBc # get pretrained model\n",
        "! gdown https://drive.google.com/uc?id=18HaWfYYZCD34VttSjd2at8b9BKdhgVgU && unzip -q val.zip # get validation dataset (2.31G) of 27kpng\n",
        "! gdown https://drive.google.com/uc?id=1it5oQDRqRzBVieX6jKNmOxj1992f63yM && unzip -q natural.zip # get natural images (0.4G) of 27kpng\n",
        "\n",
        "# rename natural images\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "filenames = [ shutil.copy(join('./natural', f), join('./natural', f).split('-')[0]+'.jpg') for f in listdir('./natural') if isfile(join('./natural', f)) ]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deep-blind-watermark-removal'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 84 (delta 23), reused 54 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (84/84), done.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1KpSJ6385CHN6WlAINqB3CYrJdleQTJBc\n",
            "To: /content/27kpng_model_best.pth.tar\n",
            "131MB [00:00, 183MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18HaWfYYZCD34VttSjd2at8b9BKdhgVgU\n",
            "To: /content/val.zip\n",
            "2.31GB [00:30, 76.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1it5oQDRqRzBVieX6jKNmOxj1992f63yM\n",
            "To: /content/natural.zip\n",
            "443MB [00:08, 49.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "-iYvIp3kpJpq",
        "outputId": "b148a5b4-5ee4-48b0-fe6f-2fbc5da1802b"
      },
      "source": [
        "import os, sys, torch,random,torchvision\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "sys.path.append('deep-blind-watermark-removal')\n",
        "sys.path.insert(0,'deep-blind-watermark-removal')\n",
        "\n",
        "from scripts.utils.imutils import im_to_numpy\n",
        "import scripts.models as models\n",
        "import scripts.datasets as datasets\n",
        "%matplotlib inline\n",
        "from PIL import Image, ImageChops\n",
        "\n",
        "def get_jet():\n",
        "    colormap_int = np.zeros((256, 3), np.uint8)\n",
        " \n",
        "    for i in range(0, 256, 1):\n",
        "        colormap_int[i, 0] = np.int_(np.round(cm.jet(i)[0] * 255.0))\n",
        "        colormap_int[i, 1] = np.int_(np.round(cm.jet(i)[1] * 255.0))\n",
        "        colormap_int[i, 2] = np.int_(np.round(cm.jet(i)[2] * 255.0))\n",
        "\n",
        "    return colormap_int\n",
        "\n",
        "def clamp(num, min_value, max_value):\n",
        "    return max(min(num, max_value), min_value)\n",
        "\n",
        "def gray2color(gray_array, color_map):\n",
        "    \n",
        "    rows, cols = gray_array.shape\n",
        "    color_array = np.zeros((rows, cols, 3), np.uint8)\n",
        " \n",
        "    for i in range(0, rows):\n",
        "        for j in range(0, cols):\n",
        "#             log(256,2) = 8 , log(1,2) = 0 * 8\n",
        "            color_array[i, j] = color_map[clamp(int(abs(gray_array[i, j])*10),0,255)]\n",
        "    \n",
        "    return color_array\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        d = dict(*args, **kwargs)\n",
        "        self.__dict__ = d\n",
        "\n",
        "jet_map = get_jet()\n",
        "\n",
        "resume_path = '27kpng_model_best.pth.tar' # path of pretrained model\n",
        "samples = [320,1364,1868] #random.sample(range(4000), 1) # show random sample \n",
        "\n",
        "data_config  = objectview({'input_size':256,\n",
        "                            'limited_dataset':0,\n",
        "                            'normalized_input':False,\n",
        "                            'data_augumentation':False,\n",
        "                            'base_dir':'.',\n",
        "                            'data':'_images'})\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(datasets.COCO('val',config=data_config,sample=samples))\n",
        "\n",
        "print('input          | target              | coarser            | final')\n",
        "print('----------------------------------------------------------------------------')\n",
        "print('predicted mask | predicted watermark | coarser difference | final difference')\n",
        "\n",
        "trans = torchvision.transforms.Compose([\n",
        "                torchvision.transforms.Resize((256,256)),\n",
        "                torchvision.transforms.ToTensor()\n",
        "            ])\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "      model = models.__dict__['vvv4n']().cuda()\n",
        "      model.load_state_dict(torch.load(resume_path)['state_dict'])\n",
        "      model.eval()\n",
        "     \n",
        "      im  = trans(Image.open(\"/content/car.jpg\").convert(\"RGB\"))\n",
        "      imoutput,immask,imwatermark = model(im)\n",
        "      imcoarser,imrefine,imwatermark = imoutput[1]*immask + im*(1-immask),imoutput[0]*immask + im*(1-immask),imwatermark*immask\n",
        "      imfinal = np.concatenate([imcoarser,imrefine,imwatermark],axis=0)\n",
        "      plt.imshow(imfinal,vmin=0.0,vmax=255.0)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total Dataset of val_images is :  3\n",
            "input          | target              | coarser            | final\n",
            "----------------------------------------------------------------------------\n",
            "predicted mask | predicted watermark | coarser difference | final difference\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e7d4e3e3e70c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m       \u001b[0mim\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"car.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m       \u001b[0mimoutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimwatermark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0mimcoarser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimrefine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimwatermark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimoutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimmask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimoutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimmask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mimmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimwatermark\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'car.jpg'"
          ]
        }
      ]
    }
  ]
}